{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from comet_ml import Experiment\n",
    "import torch\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from dataset.dataset import *\n",
    "from model.model import *\n",
    "from experiments.train import train_AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyp = {\n",
    "    'tolerance':1e-5,                                               # tolerance for the ODE Solver (refer ablation in Supplementary)\n",
    "    'ToI': 0.2,                                                     # Time of integration for each NODE block (refer discussion in Supplementary)\n",
    "    'latent_len':1000,                                              # Length of the latent embedding \n",
    "    'learning_rate':1e-4,                                           # Initial learning rate\n",
    "    'training_weights':[1,2,7],                                     # Weights corresponding to L_v, L_p1, L_p2\n",
    "    'batch_size': 15,                                               # Batch size used for training\n",
    "    'num_workers':5,                                                # Number of workers used for data loading\n",
    "    'weight_decay':0.98,                                            # Weight decay used during training\n",
    "    'num_epochs': 150,                                              # Number of epochs to train\n",
    "    'is_small': True,                                               # Set to True if want to work with a small dataset for debug/demo purposes\n",
    "    'model_folder':'./train_models/',                               # PATH to where the models are saved during training \n",
    "    'points_path': '/kunal-data/NMF_points/',                       # PATH to the directory containing Shapenet points dataset\n",
    "    'img_path': '/experiments/kunal/DATA/ShapeNetRendering/',       # PATH to the directory containing ShapeNet renderings from Choy et.al (3dr2n2)\n",
    "    'PATH_svr': './train_models_svr/epoch_370'                     # PATH where trained weights for PointsSVR are stored.\n",
    "}\n",
    "\n",
    "# train_AE(None, hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # def train_SVR():\n",
    "# # with torch.no_grad():\n",
    "\n",
    "# #     print(\"*********** INITIALIZATION  ************\")\n",
    "# #     torch.cuda.set_device(0)\n",
    "# #     encoder_type = 'point'\n",
    "# #     training_generator = get_dataloader(encoder_type, 15, 5,split='test')\n",
    "# #     model = nn.DataParallel(NeuralMeshFlow(encoder_type = encoder_type, zdim=1000, time=0.2).cuda())\n",
    "# #     load_partial_pretrained(model, '/kunal-data/NeuralMeshFlow/nmf_points/th-1e-05/model_point-117')\n",
    "\n",
    "# #     model.eval()\n",
    "    \n",
    "# with torch.no_grad():\n",
    "#     torch.cuda.set_device(0)\n",
    "#     encoder_type = 'point'\n",
    "#     training_generator = get_dataloader(encoder_type, hyp, split = 'test')\n",
    "#     model = nn.DataParallel(NeuralMeshFlow(encoder_type = encoder_type, zdim=1000, time=0.2)).cuda()\n",
    "#     model.load_state_dict(torch.load('./train_models/epoch_149'))\n",
    "#     model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     for input,_,_ in training_generator:\n",
    "#         input = input.cuda()\n",
    "# #         ptcld = ptcld[:,:256,:]\n",
    "# #         ptcld = ptcld - torch.mean(input, axis=1, keepdim=True) \n",
    "\n",
    "# #         pred, pred_refined, face = model(ptcld, img=None)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !!! Using small dataset of size 100 !!!  \n",
      "total models for testing :  100\n",
      "Dataloader for images with Batch Size : 15 and 5 workers created for testing.\n",
      "Neural Mesh Flow with 1000 length embedding initialized\n",
      "Choosing image encoder\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.set_device(0)\n",
    "    encoder_type = 'image'\n",
    "    training_generator = get_dataloader(encoder_type, hyp, split = 'test')\n",
    "    model = nn.DataParallel(NeuralMeshFlow(encoder_type = encoder_type,PATH_svr=hyp['PATH_svr'], zdim=1000, time=0.2)).cuda()\n",
    "    model.load_state_dict(torch.load('./train_models/epoch_149'))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for input,gtpt,_,_ in training_generator:\n",
    "        input = input.cuda()\n",
    "#         ptcld = ptcld[:,:256,:]\n",
    "#         ptcld = ptcld - torch.mean(input, axis=1, keepdim=True) \n",
    "\n",
    "#         pred, pred_refined, face = model(ptcld, img=None)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred0, pred, pred_refined, face = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.max(torch.norm(ptcld, dim=2), dim=1)\n",
    "idx = 4\n",
    "vertices = pred_refined[idx,...].detach().cpu().numpy()\n",
    "faces = face[idx,...].detach().cpu().numpy()\n",
    "mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n",
    "mesh.export('test.obj');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
